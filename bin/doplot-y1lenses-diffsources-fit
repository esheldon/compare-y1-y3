#!/usr/bin/env python
"""
TODO:
    - get lens bin z values, at the mean
    - boost correct y1 values (use Y3 for now)

"""

import fitsio
import numpy as np
import esutil as eu
import hickory
from compare_y1_y3.util import (
    Y3_MVALS,
    Y1_MVAL,
    Y1_CHI_FACTORS,
    Y1_ZS_OFFSETS,
    interpolate_y1_onto_y3,
    inv_sigma_crit_eff_fast,
    get_mean_z,
    jackknife_ratio,
)
import dsfit

# public data vectors for Y1
y1lenses_y1sources = '2pt_NG_mcal_1110.fits'

# y1lenses_y3sources = '/home/esheldon/git/xcorr/runs/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT/zslim_som/zs_som/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/gt_boosted_twopointfile.fits'  # noqa

# we use the unboosted data vectors for comparision with Y1 unboosted data
# y1lenses_y3sources_noboost = '/home/esheldon/git/xcorr/runs/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT/zslim_som/zs_som/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/gt_twopointfile.fits'  # noqa

# new version limiting y3 sources to y1 footprint and using mean R from
# that


y1lenses_y3sources_noboost_y1area = '~/git/xcorr/runs/y1lenses/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT_y1footprint/zslim_som/zs_som/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/gt_twopointfile.fits'  # noqa

y1lenses_y3sources_boosted_y1area = '~/git/xcorr/runs/y1lenses/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT_y1footprint/zslim_som/zs_som/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/gt_boosted_twopointfile.fits'  # noqa

# y1lenses_y3sources_boost_factors = '~/git/xcorr/runs/y1lenses/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT_y1footprint/zslim_som/zs_som/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/boost_factor_twopointfile.fits'  # noqa

# Y1 but run with new pipeline, so only will use boost factors
y1lenses_y1sources_boost_factors = '~/git/xcorr/runs/y1sources/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT/zslim_y1/zs_bpz/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/boost_factor_twopointfile.fits'  # noqa

y1lenses_y1sources_boosted = '~/git/xcorr/runs/y1sources/Y3_mastercat___UNBLIND___final_v1.0_DO_NOT_USE_FOR_2PT/zslim_y1/zs_bpz/redmagic_y1/zllim_y1/lens_w_True/njk_150/thbin_2.50_250_20/bslop_0/source_only_close_to_lens_True_nside4/measurement/gt_boosted_twopointfile.fits'  # noqa

# we need to get the n(zl) from here, the new run did not have the correct
# values in it
# also has gammat for y3y3
y3sources = '2pt_NG_final_2ptunblind_11_13_20_wnz.fits'


# (sbin, lbin),
BINS2FIT = [
    (1, 1),
    (1, 2),
    (1, 3),  # marginal
    (1, 4),  # *
    # (1, 5),  # *
    #
    (2, 1),
    (2, 2),
    (2, 3),
    (2, 4),   # *
    # (2, 5),   # *
    #
    (3, 1),
    (3, 2),
    (3, 3),
    (3, 4),  # *
    # (3, 5),  # *
    #
    (4, 1),
    (4, 2),
    (4, 3),
    (4, 4),  # *
    # (4, 5),  # *

]
# BINS2FIT = [
#     (1, 1),
#     (2, 1),
#     (3, 1),
#     (4, 1),
#
#     (1, 2),
#     (2, 2),
#     (3, 2),
#     (4, 2),
#
#     (1, 3),  # marginal
#     # (1, 4),  # *
#     #
#     (2, 3),
#     # (2, 4),   # *
#     #
#     (3, 3),
#     # (3, 4),  # *
#     #
#     (4, 3),
#     # (4, 4),  # *
#
#     (1, 4),
#     (2, 4),
#     (3, 4),
#     (4, 4),
#
#
# ]
#
# BINS2FIT = [(4, 4)]


def get_args():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument('--seed', type=int, required=True)
    parser.add_argument('--ntrial', type=int, default=1000)
    parser.add_argument('--sample', action='store_true')
    parser.add_argument('--use-y1-m', action='store_true')
    parser.add_argument(
        '--use-rerun', action='store_true',
        help='use the rerun of Y1 sources and lenses using Y3 code',
    )
    return parser.parse_args()


def read_data_rerun():
    """
    read data for both y1 and y3 sources.
    Returns
    --------
    data: dict
        Dictionary of arrays, keyed by
            y1y1: y1 lenses, y1 sources
            y1y3: y1 lenses, y3 sources
        The data for each key is
            'gammat': The gamma_t data vector for all l/s bins
            'nzl': redshift and n(z) for the lenses for all l/s bins
            'nzs': redshift and n(z) for the sources for all l/s bins
    """

    sname_y1y3 = 'nz_source_realisation_%d'

    with fitsio.FITS(y3sources, lower=True) as fits:
        nzs = fits['nz_source'][:]
        nzs_samples = []
        for i in range(1000):
            sname = sname_y1y3 % i
            tmp = fits[sname][:]
            nzs_samples.append(tmp)

    gt_y1y1 = fitsio.read(
        y1lenses_y1sources_boosted, ext='gammat', lower=True,
    )
    gtcov_y1y1 = fitsio.read(
        y1lenses_y1sources_boosted, ext='covmat', lower=True,
    )

    gt_y1y3 = fitsio.read(
        y1lenses_y3sources_boosted_y1area, ext='gammat', lower=True,
    )
    gtcov_y1y3 = fitsio.read(
        y1lenses_y3sources_boosted_y1area, ext='covmat', lower=True,
    )

    data = {
        'y1y1': {
            'gammat': gt_y1y1,
            'gammat_cov': gtcov_y1y1,
            'nzl': fitsio.read(y1lenses_y1sources, ext='nz_lens', lower=True),  # noqa
            'nzs': fitsio.read(y1lenses_y1sources, ext='nz_source', lower=True),  # noqa
        },
        'y1y3': {
            'gammat': gt_y1y3,
            'gammat_cov':  gtcov_y1y3,
            'nzl': fitsio.read(y1lenses_y1sources, ext='nz_lens', lower=True),  # noqa
            'nzs_samples': nzs_samples,
            'nzs': nzs,
        }
    }

    if False:
        plt = hickory.Plot(figsize=(8, 8))
        plt.imshow(data['y1y3']['gammat_cov'])
        plt.show(dpi=300)

    return data


def read_data():
    """
    read data for both y1 and y3 sources.
    Returns
    --------
    data: dict
        Dictionary of arrays, keyed by
            y1y1: y1 lenses, y1 sources
            y1y3: y1 lenses, y3 sources
        The data for each key is
            'gammat': The gamma_t data vector for all l/s bins
            'nzl': redshift and n(z) for the lenses for all l/s bins
            'nzs': redshift and n(z) for the sources for all l/s bins
    """

    bfdata = fitsio.read(
        y1lenses_y1sources_boost_factors,
        ext='boost_factor', lower=True,
    )
    boost_factors = bfdata['value']

    sname_y1y3 = 'nz_source_realisation_%d'

    with fitsio.FITS(y3sources, lower=True) as fits:
        nzs = fits['nz_source'][:]
        nzs_samples = []
        for i in range(1000):
            sname = sname_y1y3 % i
            tmp = fits[sname][:]
            nzs_samples.append(tmp)

    gt_y1y1 = fitsio.read(y1lenses_y1sources, ext='gammat', lower=True)
    num = gt_y1y1['value'].size

    gtcov_y1y1 = fitsio.read(y1lenses_y1sources, ext='covmat', lower=True)
    gtcov_y1y1 = gtcov_y1y1[400:400+num, 400:400+num]

    gt_y1y3 = fitsio.read(
        y1lenses_y3sources_boosted_y1area, ext='gammat', lower=True,
    )
    gtcov_y1y3 = fitsio.read(
        y1lenses_y3sources_boosted_y1area, ext='covmat', lower=True,
    )

    gt_y1y1['value'] *= boost_factors
    # gt_y1y3['value'] *= boost_factors

    data = {
        'y1y1': {
            'gammat': gt_y1y1,
            'gammat_cov': gtcov_y1y1,
            'nzl': fitsio.read(y1lenses_y1sources, ext='nz_lens', lower=True),  # noqa
            'nzs': fitsio.read(y1lenses_y1sources, ext='nz_source', lower=True),  # noqa
        },
        'y1y3': {
            'gammat': gt_y1y3,
            'gammat_cov':  gtcov_y1y3,
            # 'gammat':  fitsio.read(y3sources, ext='gammat', lower=True),  # noqa
            # 'gammat_cov':  fitsio.read(y3sources, ext='covmat', lower=True)[400:, 400:],  # noqa
            # 'nzl': fitsio.read(y1lenses_y3sources_noboost_y1area, ext='nz_lens', lower=True),  # noqa
            'nzl': fitsio.read(y1lenses_y1sources, ext='nz_lens', lower=True),  # noqa
            'nzs_samples': nzs_samples,
            'nzs': nzs,
        }
    }

    if False:
        plt = hickory.Plot(figsize=(8, 8))
        plt.imshow(data['y1y3']['gammat_cov'])
        plt.show(dpi=300)

    return data


def get_nofz(*, data, lbin, sbin, sample=False):
    """
    get n(z) data for the given lens and source bin.  A random y3 source n(z)
    is used each time this code is called


    the Y1 n(z) are shifted according to the prior each time this is called

    data: dict
        Dictionary of arrays, keyed by
            y1y1: y1 lenses, y1 sources
            y1y3: y1 lenses, y3 sources
        The data for each key is
            'gammat': The gamma_t data vector for all l/s bins
            'nzl': redshift and n(z) for the lenses for all l/s bins
            'nzs': redshift and n(z) for the sources for all l/s bins
    lbin: int
        lens bin, 1 offset
    sbin: int
        source bin, 1 offst

    Returns
    -------
    dict keyed by y1y1 or y1y3 with the particular data from the
    requested lens/source bins.  Each key has entries
        'lzbin': lens z grid
        'lnofz': n(zl) on the grid
        'szbin': source z grid
        'snofz': n(zs) on z grid
    """

    if sample:
        nsamp = len(data['y1y3']['nzs_samples'])
        i = np.random.randint(nsamp)
        y1y3_nzs = data['y1y3']['nzs_samples'][i]
    else:
        y1y3_nzs = data['y1y3']['nzs']

    lbin_name = 'bin%d' % lbin
    sbin_name = 'bin%d' % sbin

    moff = Y1_ZS_OFFSETS[sbin-1][0]
    woff = Y1_ZS_OFFSETS[sbin-1][1]
    if sample:
        z1off = np.random.normal(
            loc=moff,
            scale=woff,
        )
    else:
        z1off = moff

    y1_zs = data['y1y1']['nzs']['z_mid'] + z1off

    w, = np.where(y1_zs > 0)
    y1_zs = y1_zs[w]
    y1_nofzs = data['y1y1']['nzs'][sbin_name][w]

    zdata = {
        'y1y1': {
            'lzbin': data['y1y1']['nzl']['z_mid'],
            'lnofz': data['y1y1']['nzl'][lbin_name],
            'szbin': y1_zs,
            'snofz': y1_nofzs,
        },
        'y1y3': {
            'lzbin': data['y1y3']['nzl']['z_mid'],
            'lnofz': data['y1y3']['nzl'][lbin_name],
            'szbin': y1y3_nzs['z_mid'],
            'snofz': y1y3_nzs[sbin_name],
        }
    }
    return zdata


def get_oneplusm(*, sbin, sample=False, use_y1_m=False):
    """
    """
    y3_oneplusm = 1 + Y3_MVALS[sbin-1][0]

    if use_y1_m:
        y1_oneplusm = 1 + Y1_MVAL
    else:
        y1_oneplusm = y3_oneplusm

        if sample:
            y1_oneplusm += np.random.normal(scale=Y3_MVALS[sbin-1][1])

    return y1_oneplusm, y3_oneplusm


def add_rescaled_data(*, data, cosmo_pars, sample=False, use_y1_m=False):

    npts = data['y1y3']['gammat']['value'].size  # - 4*20
    data['y1y1']['r'] = np.zeros(npts)
    data['y1y1']['ds'] = np.zeros(npts)
    data['y1y1']['dscov'] = np.zeros((npts, npts))

    data['y1y3']['r'] = np.zeros(npts)
    data['y1y3']['ds'] = np.zeros(npts)
    data['y1y3']['dscov'] = np.zeros((npts, npts))

    for lbin in range(1, 5+1):
        for sbin in range(1, 4+1):

            zdata = get_nofz(data=data, lbin=lbin, sbin=sbin, sample=sample)

            siginv_y1y1 = inv_sigma_crit_eff_fast(
                zlbin=zdata['y1y1']['lzbin'],
                nzl=zdata['y1y1']['lnofz'],
                zsbin=zdata['y1y1']['szbin'],
                nzs=zdata['y1y1']['snofz'],
                cosmo_pars=cosmo_pars,
                # zsbin=zdata['y1y3']['szbin'],
                # nzs=zdata['y1y3']['snofz'],
            )
            siginv_y1y3 = inv_sigma_crit_eff_fast(
                zlbin=zdata['y1y3']['lzbin'],
                nzl=zdata['y1y3']['lnofz'],
                zsbin=zdata['y1y3']['szbin'],
                nzs=zdata['y1y3']['snofz'],
                cosmo_pars=cosmo_pars,
            )

            data['y1y1']['zl_mean'] = get_mean_z(
                z=zdata['y1y1']['lzbin'],
                nz=zdata['y1y1']['lnofz'],
            )
            data['y1y3']['zl_mean'] = data['y1y1']['zl_mean']
            # print('mean zlens:', data['y1y1']['zl_mean'])
            # print('siginv_y1y1:', siginv_y1y1)
            # print('siginv_y1y3:', siginv_y1y3)

            y1_oneplusm, y3_oneplusm = get_oneplusm(
                sbin=sbin, sample=sample, use_y1_m=use_y1_m,
            )

            wy1y1, = np.where(
                (data['y1y1']['gammat']['bin1'] == lbin) &
                (data['y1y1']['gammat']['bin2'] == sbin)
            )
            wy1y3, = np.where(
                (data['y1y3']['gammat']['bin1'] == lbin) &
                (data['y1y3']['gammat']['bin2'] == sbin)
            )

            fac_y1y1 = 1.0/y1_oneplusm/siginv_y1y1
            fac_y1y3 = 1.0/y3_oneplusm/siginv_y1y3

            ds_y1y1 = data['y1y1']['gammat']['value'][wy1y1] * fac_y1y1
            ds_y1y3 = data['y1y3']['gammat']['value'][wy1y3] * fac_y1y3

            rad_y1y1 = np.deg2rad(data['y1y1']['gammat']['ang'][wy1y1]/60)
            r_y1y1 = rad_y1y1*Y1_CHI_FACTORS[lbin-1]
            rad_y1y3 = np.deg2rad(data['y1y3']['gammat']['ang'][wy1y3]/60)
            r_y1y3 = rad_y1y3*Y1_CHI_FACTORS[lbin-1]

            data['y1y1']['r'][wy1y1] = r_y1y1
            data['y1y3']['r'][wy1y3] = r_y1y3

            ds_y1y1_interp = interpolate_y1_onto_y3(r_y1y3, r_y1y1, ds_y1y1)

            imin, imax = wy1y1[0], wy1y1[-1]+1
            # print('sbin, lbin:', imin, imax)
            cov_y1y1 = (
                data['y1y1']['gammat_cov'][imin:imax, imin:imax] * fac_y1y1**2
            )
            imin, imax = wy1y3[0], wy1y3[-1]+1
            cov_y1y3 = (
                data['y1y3']['gammat_cov'][imin:imax, imin:imax] * fac_y1y3**2
            )
            # print('imin, imax:', imin, imax)

            # ds*r**pow == constant
            # same as fitting ds to 1/r**pow

            # data['y1y1']['ds'][wy1y1] = ds_y1y1
            data['y1y1']['ds'][wy1y1] = ds_y1y1_interp
            data['y1y1']['dscov'][imin:imax, imin:imax] = cov_y1y1

            data['y1y3']['ds'][wy1y3] = ds_y1y3
            data['y1y3']['dscov'][imin:imax, imin:imax] = cov_y1y3


def do_one_fit(*, rng, data, sbin, lbin, plt, cosmo_pars):
    w, = np.where(
        (data['gammat']['bin1'] == lbin) &
        (data['gammat']['bin2'] == sbin)
    )
    imin, imax = w[0], w[-1]+1

    r = data['r'][w]
    dsig = data['ds'][w]
    dsigcov = data['dscov'][imin:imax, imin:imax]

    fitter = dsfit.NFWBiasFitter(
        z=data['zl_mean'],
        r=r,
        cosmo_pars=cosmo_pars,
    )

    B_bounds = [0.3, 2.0]
    c_bounds = [0.1, 5.0]

    r200_guess = 0.3*rng.uniform(low=0.9, high=1.1)
    c_guess = rng.uniform(low=c_bounds[0], high=c_bounds[1])
    B_guess = rng.uniform(low=B_bounds[0], high=B_bounds[1])
    guess = np.array([r200_guess, c_guess, B_guess])

    res = fitter.fit(
        dsig=dsig,
        dsigcov=dsigcov,
        guess=guess,
        c_bounds=c_bounds,
        B_bounds=B_bounds,
    )

    print('-'*70)
    print('sbin %d, lbin %d' % (sbin, lbin))
    print('r200: %(r200)g +/- %(r200_err)g' % res)
    print('c: %(c)g +/- %(c_err)g' % res)
    print('B: %(B)g +/- %(B_err)g' % res)
    print('m200: %(m200)g +/- %(m200_err)g' % res)

    dsfit.fit.plot(
        r=r,
        z=data['zl_mean'],
        r200=res['r200'],
        c=res['c'],
        B=res['B'],
        dsig=dsig,
        dsigcov=dsigcov,
        # xlim=(0.25, 65),
        # xlim=(0.25, 185),
        # ylim=(0.025, 45),
        plt=plt,
    )
    x = 0.075
    plt.ntext(x, 0.25, 'sbin: %d, lbin: %d' % (sbin, lbin))
    plt.ntext(x, 0.20, r'm200: %(m200).3g $\pm$ %(m200_err).3g' % res)
    plt.ntext(x, 0.15, r'B: %(B).3g $\pm$ %(B_err).3g' % res)
    plt.ntext(x, 0.10, r'c: %(c).3g $\pm$ %(c_err).3g' % res)
    # plt.show()

    return res


def do_fit(*, rng, data, lbin, sbin, cosmo_pars, plt1, plt3):
    res_y1y1 = do_one_fit(
        rng=rng, data=data['y1y1'],
        lbin=lbin, sbin=sbin, plt=plt1,
        cosmo_pars=cosmo_pars,
    )
    res_y1y3 = do_one_fit(
        rng=rng, data=data['y1y3'],
        lbin=lbin, sbin=sbin, plt=plt3,
        cosmo_pars=cosmo_pars,
    )

    return res_y1y1, res_y1y3


def make_table():
    tab = hickory.Table(
        nrows=4,
        ncols=4,
        # figsize=(14, 9.3),
        figsize=(16, 14),
        # figsize=(18, 14),
    )
    for ax in tab.axes:
        ax.set(
            xlabel=r"$r$ [Mpc]",
            ylabel=r"$\Delta\Sigma ~ [\mathrm{M}_{\odot} \mathrm{pc}^{-2}]$",
            xlim=(0.25, 185),
            ylim=(0.025, 45),
        )
        ax.set_xscale('log')
        ax.set_yscale('log')

    return tab


def do_fits(*, rng, data, cosmo_pars):

    tab_y1y1 = make_table()
    tab_y1y3 = make_table()
    reslist = []

    iax = 0
    for sbin, lbin in BINS2FIT:
        res_y1y1, res_y1y3 = do_fit(
            rng=rng, data=data, lbin=lbin, sbin=sbin,
            plt1=tab_y1y1.axes[iax],
            plt3=tab_y1y3.axes[iax],
            cosmo_pars=cosmo_pars,
        )

        reslist.append({
            'y1y1': res_y1y1,
            'y1y3': res_y1y3,
        })

        iax += 1

    tab_y1y1.axes[0].legend()
    tab_y1y3.axes[0].legend()

    return reslist, tab_y1y1, tab_y1y3


def make_comb(n):
    return {
        'm200': np.zeros(n),
        'm200_err': np.zeros(n),
        'c': np.zeros(n),
        'c_err': np.zeros(n),
        'B': np.zeros(n),
        'B_err': np.zeros(n),
    }


def get_stat(*, comb_y1y1, comb_y1y3, key, dolog):

    y1y1vals = comb_y1y1[key]
    y1y3vals = comb_y1y3[key]
    plot2hist(
        data_y1y1=y1y1vals,
        data_y1y3=y1y3vals,
        key=key,
        dolog=dolog,
    )

    y1y1_mean, y1y1_err = eu.stat.wmom(
        y1y1vals,
        1.0/comb_y1y1['%s_err' % key]**2,
        calcerr=True,
    )
    y1y3_mean, y1y3_err = eu.stat.wmom(
        y1y3vals,
        1.0/comb_y1y3['%s_err' % key]**2,
        calcerr=True,
    )

    print('%s means:' % key)
    print('y1y1: %g +/- %g' % (y1y1_mean, y1y1_err))
    print('y1y3: %g +/- %g' % (y1y3_mean, y1y3_err))

    # avg = 0.5*(y1y1_mean + y1y3_mean)
    # rat = y1y1_mean/y1y3_mean
    # rat_err = rat * np.sqrt(np.abs(y1y1_err**2 - y1y3_err**2)) / avg

    rat, rat_err = jackknife_ratio(
        data1=y1y1vals,
        weights1=1.0/comb_y1y1['%s_err' % key]**2,
        data2=y1y3vals,
        weights2=1.0/comb_y1y3['%s_err' % key]**2,
    )
    print('ratio of means:  %g +/- %g' % (rat, rat_err))


def plot_hist_rat(data, key):
    plt = hickory.Plot(
        xlabel=r'$\mathrm{log}_{10}(%s^{y1}/%s^{y3})$' % (key, key)
    )
    plt.hist(np.log10(data), bins=20)
    plt.show()


def plot2hist(*, data_y1y1, data_y1y3, key, dolog=True):

    if dolog:
        xlabel = r'$\mathrm{log}_{10}(%s)$' % key

        ld1 = np.log10(data_y1y1)
        ld3 = np.log10(data_y1y3)
    else:
        xlabel = key
        ld1 = data_y1y1
        ld3 = data_y1y3

    plt = hickory.Plot(
        xlabel=xlabel,
    )

    xmin = min(ld1.min(), ld3.min())
    xmax = max(ld1.max(), ld3.max())

    binsize = 0.2*ld1.std()

    alpha = 0.5
    plt.hist(
        ld1,
        min=xmin, max=xmax,
        binsize=binsize, label='y1y1',
        alpha=alpha,
    )
    plt.hist(
        ld3,
        min=xmin, max=xmax,
        binsize=binsize, label='y1y3',
        alpha=alpha,
    )
    plt.legend()
    # plt.show()
    fname = '%s-hists.png' % key
    print('writing:', fname)
    plt.savefig(fname, dpi=150)

    return plt


def get_stats(*, reslist):
    num = len(reslist)
    comb_y1y1 = make_comb(num)
    comb_y1y3 = make_comb(num)

    for i, res in enumerate(reslist):
        for key in comb_y1y1:
            comb_y1y1[key][i] = res['y1y1'][key]
            comb_y1y3[key][i] = res['y1y3'][key]

    print('-'*70)
    for key in ['m200', 'B']:
        if key == 'm200':
            dolog = False
        else:
            dolog = False

        get_stat(
            comb_y1y1=comb_y1y1, comb_y1y3=comb_y1y3, key=key,
            dolog=dolog,
        )


def main():
    args = get_args()
    rng = np.random.RandomState(args.seed)

    cosmo_pars = dsfit.cosmopars.get_cosmo_pars()

    if args.use_rerun:
        data = read_data_rerun()
    else:
        data = read_data()

    y1y1_fname = 'fits-y1y1.png'
    y1y3_fname = 'fits-y1y3.png'
    if args.use_y1_m:
        y1y1_fname = y1y1_fname.replace('.png', '-y1m.png')
        y1y3_fname = y1y3_fname.replace('.png', '-y1m.png')
    if args.use_rerun:
        y1y1_fname = y1y1_fname.replace('.png', '-rerun.png')
        y1y3_fname = y1y3_fname.replace('.png', '-rerun.png')

    if args.sample:
        raise RuntimeError('set up sampling')
        for i in range(args.ntrial):
            add_rescaled_data(
                data=data, sample=args.sample,
                use_y1_m=args.use_y1_m,
                cosmo_pars=cosmo_pars,
            )
            reslist, tab_y1y1, tab_y1y3 = do_fits(
                rng=rng, data=data, cosmo_pars=cosmo_pars,
            )

    else:
        add_rescaled_data(
            data=data, use_y1_m=args.use_y1_m,
            cosmo_pars=cosmo_pars,
        )
        reslist, tab_y1y1, tab_y1y3 = do_fits(
            rng=rng, data=data, cosmo_pars=cosmo_pars,
        )
        get_stats(reslist=reslist)

        dpi = 75
        print('writing:', y1y1_fname)
        tab_y1y1.savefig(y1y1_fname, dpi=dpi)
        print('writing:', y1y3_fname)
        tab_y1y3.savefig(y1y3_fname, dpi=dpi)

    # print('amp: %g +/- %g' % (amp, amp_err))


if __name__ == '__main__':
    main()
